{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning with Functional API"
      ],
      "metadata": {
        "id": "ynJOiq3W5Duh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "TZt_LhXlomEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "RGdC7qLz5JHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref=ZipFile('/content/drive/MyDrive/Research Data/Colab Notebooks/MSc 2023/Week 12/10_food_classes_10_percent.zip')"
      ],
      "metadata": {
        "id": "9JN9caqk5MkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref.extractall()"
      ],
      "metadata": {
        "id": "NPMEVt1N5OSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir='/content/10_food_classes_10_percent/train'\n",
        "train_dir='/content/10_food_classes_10_percent/test'"
      ],
      "metadata": {
        "id": "TrZqhdNU5kpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use IDFD"
      ],
      "metadata": {
        "id": "X4VbumfzaYGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDG reminder NOW old\n"
      ],
      "metadata": {
        "id": "LK-MJNJXaWH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE=(224,224)\n",
        "BATCH_SIZE=32"
      ],
      "metadata": {
        "id": "Zu7Bg0f9X5Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_IDG= ImageDataGenerator(rescale=1/255.)   #note  255.\n",
        "test_IDG = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "IMAGE_SHAPE=(224,224)\n",
        "BATCH_SIZE=30\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_IDG = train_IDG.flow_from_directory(train_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data_IDG = test_IDG.flow_from_directory(test_dir,\n",
        "                                              target_size=IMAGE_SHAPE,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "r_zQvmYgBLLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_IDG.class_indices"
      ],
      "metadata": {
        "id": "fvzTGXSmB5ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IDFD\n",
        "This is the MODERN way"
      ],
      "metadata": {
        "id": "iAdc_tOXCAzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "IKUTtFXhLBAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE=(224,224)\n",
        "BATCH_SIZE=32"
      ],
      "metadata": {
        "id": "pACviyU-ByJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training images:\")\n",
        "train_data_IDFD= image_dataset_from_directory(train_dir,\n",
        "                                             label_mode='categorical',\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMAGE_SHAPE)\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data_IDFD=image_dataset_from_directory(test_dir,\n",
        "                                            label_mode='categorical',\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            image_size=IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "0dXy90kB5x0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_IDFD.class_names"
      ],
      "metadata": {
        "id": "tjZNohug5ypl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in test_data_IDFD.take(1):  # Take one batch\n",
        "    print(\"Labels for this batch:\")\n",
        "    print(labels.numpy())  # Convert Tensor to NumPy array for better visualization"
      ],
      "metadata": {
        "id": "88WylAzn80Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(np.array(images[0],dtype=np.int64).reshape((224, 224, 3)))\n"
      ],
      "metadata": {
        "id": "Y8Phk34H9aRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lets start with making our functional model"
      ],
      "metadata": {
        "id": "YRb86zMTcIWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n"
      ],
      "metadata": {
        "id": "AJ83ZRVtDEOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing using tf.keras Sequential API\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1.0 / 255),  # Scale pixel values to [0, 1]\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),  # Random horizontal and vertical flips\n",
        "    tf.keras.layers.RandomRotation(0.2),  # Rotate images randomly up to 20%\n",
        "    tf.keras.layers.RandomZoom(0.2),  # Random zoom in/out by 20%\n",
        "], name=\"data_augmentation\")"
      ],
      "metadata": {
        "id": "dttWDgDnCYFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets get the model we are going to transfer learn from"
      ],
      "metadata": {
        "id": "V6U2Rdxxc-9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model without the top (fully connected) layers\n",
        "trans_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,  # Exclude the top classification layers\n",
        "    weights='imagenet',  # Use ImageNet-pretrained weights\n",
        "    input_shape=(224, 224, 3)  # Define the input shape if necessary\n",
        ")\n",
        "\n",
        "# Freeze the pre-trained layers so they do not update during training\n",
        "trans_model.trainable = False"
      ],
      "metadata": {
        "id": "zyzmsyATDAPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the last few layers for fine-tuning\n",
        "for layer in trans_model.layers[-10:]:  # Fine-tune the last 10 layers\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "UTrNvDX0VTGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(224,224,3)"
      ],
      "metadata": {
        "id": "uNUkke5IDP4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the first Functional Model, we call it model_1"
      ],
      "metadata": {
        "id": "_KFSmAUDdoiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Input layer\n",
        "inputs = layers.Input(shape=input_shape, name='Input')\n",
        "print(f\"Input shape: {inputs.shape}\")\n",
        "\n",
        "# Optional: Rescaling (normalize pixel values to [0, 1])\n",
        "x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "print(f\"After Rescaling: {x.shape}\")\n",
        "\n",
        "# First convolutional layer\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', name='Conv_1')(x)\n",
        "print(f\"After Conv_1: {x.shape}\")\n",
        "\n",
        "# First pooling layer\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), name='Pool_1')(x)\n",
        "print(f\"After Pool_1: {x.shape}\")\n",
        "\n",
        "# Second convolutional layer\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu', name='Conv_2')(x)\n",
        "print(f\"After Conv_2: {x.shape}\")\n",
        "\n",
        "# Second pooling layer\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), name='Pool_2')(x)\n",
        "print(f\"After Pool_2: {x.shape}\")\n",
        "\n",
        "# Lets compare global pooling vs Flattening\n",
        "#x = layers.Flatten(name='Flatten')(x)\n",
        "x = layers.GlobalAveragePooling2D(name='Global_Avg_Pooling')(x)\n",
        "print(f\"After CHOICE Pooling: {x.shape}\")\n",
        "\n",
        "# Output layer (10 classes with softmax activation)\n",
        "outputs = layers.Dense(10, activation='softmax', name='Output_Layer')(x)\n",
        "print(f\"After Output Layer: {outputs.shape}\")\n",
        "\n",
        "# Finalize the model\n",
        "functional_model_1 = tf.keras.Model(inputs=inputs, outputs=outputs, name='Basic_Model')\n"
      ],
      "metadata": {
        "id": "JSu9-0Q2WEOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Define the input layer\n",
        "inputs = layers.Input(shape=input_shape, name='Input')\n",
        "print(f\"Input shape: {inputs.shape}\")\n",
        "\n",
        "# Optional: Rescaling (use this if the pre-trained model does not include rescaling)\n",
        "x = layers.Rescaling(1.0 / 255, name='Rescaling')(inputs)\n",
        "print(f\"After Rescaling: {x.shape}\")\n",
        "\n",
        "# Attach the pre-trained transfer learning model (e.g., ResNet50)\n",
        "x = trans_model(x, training=False)  # Set training=False to freeze pre-trained weights\n",
        "print(f\"After Transfer Learning Model: {x.shape}\")\n",
        "\n",
        "# Global Average Pooling to reduce dimensions and create a feature vector\n",
        "x = layers.GlobalAveragePooling2D(name='Global_Avg_Pooling')(x)\n",
        "print(f\"After Global Average Pooling: {x.shape}\")\n",
        "\n",
        "# Add a custom dense layer for classification (output layer)\n",
        "outputs = layers.Dense(10, activation='softmax', name='Output_Layer')(x)\n",
        "print(f\"After Output Layer: {outputs.shape}\")\n",
        "\n",
        "# Finalize the model\n",
        "functional_model_trans = tf.keras.Model(inputs=inputs, outputs=outputs, name='Transfer_Learning_Model')"
      ],
      "metadata": {
        "id": "XBx6pyc8XJWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(functional_model_1)"
      ],
      "metadata": {
        "id": "e1jHsFIkDcbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(trans_model, expand_nested=True, to_file='trans_model_simple.pdf')"
      ],
      "metadata": {
        "id": "FoCmcUxQXqIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from this point onward, everything is just similar to the sequential API\n",
        "functional_model_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6rjDM7AWDmK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "functional_model_trans.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "O9YF1t5rYudY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "7Tx6MDmHFlC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0=datetime.now()\n",
        "\n",
        "history_1=functional_model_1.fit(train_data_IDFD,\n",
        "            epochs=5,\n",
        "            #steps_per_epoch=len(train_data_IDFD),\n",
        "            validation_data=test_data_IDFD,)\n",
        "            #validation_steps=len(test_data_IDFD),)\n",
        "\n",
        "print(datetime.now())\n",
        "\n",
        "t1=datetime.now()\n",
        "print(t1-t0)"
      ],
      "metadata": {
        "id": "3RWk9H6BFPg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0=datetime.now()\n",
        "\n",
        "history_trans=functional_model_trans.fit(train_data_IDFD,\n",
        "            epochs=3,\n",
        "            #steps_per_epoch=len(train_data_IDFD),\n",
        "            validation_data=test_data_IDFD,)\n",
        "            #validation_steps=len(test_data_IDFD),)\n",
        "\n",
        "print(datetime.now())\n",
        "\n",
        "t1=datetime.now()\n",
        "print(t1-t0)"
      ],
      "metadata": {
        "id": "Q18pbxvHZT_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Model Checkpoint callback"
      ],
      "metadata": {
        "id": "6DcP8brvM3Nz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets make a new check point to save the weights of our model when it is trained"
      ],
      "metadata": {
        "id": "2NILfKdmm8uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path='/content/my_model_chk.weights.h5' # make sure our create the file path before puting iut here\n",
        "\n",
        "chk_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_weights_only=True,\n",
        "                                                save_best_only=False,\n",
        "                                                save_freq='epoch')"
      ],
      "metadata": {
        "id": "ZhEwICvYOVa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filepath=checkpoint_path:\n",
        "\n",
        "The path where the weights will be saved.\n",
        "Example: model_4.ckpt will store the weights after each save.\n",
        "save_weights_only=True:\n",
        "\n",
        "Saves only the model's weights, not the entire model structure.\n",
        "Use this when you want to load the model structure separately (useful for transfer learning or sharing pre-trained weights).\n",
        "save_best_only=False:\n",
        "\n",
        "If False, the weights are saved at the end of every epoch.\n",
        "If True, the model saves weights only when it improves the monitored metric (e.g., validation loss).\n",
        "save_freq='epoch':\n",
        "\n",
        "Specifies when to save the weights.\n",
        "'epoch': Saves at the end of each epoch.\n",
        "Alternatively, you can set a specific number (e.g., save_freq=5 saves every 5 steps)."
      ],
      "metadata": {
        "id": "79du39rhaTaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t0=datetime.now()\n",
        "\n",
        "history_ck=functional_model_trans.fit(train_data_IDFD,\n",
        "            epochs=3,\n",
        "            #steps_per_epoch=len(train_data_IDFD),\n",
        "            validation_data=test_data_IDFD,\n",
        "            #validation_steps=len(test_data_IDFD),\n",
        "            callbacks=[chk_callback]) # we are adding our checkpoint here\n",
        "\n",
        "print(datetime.now())\n",
        "\n",
        "t1=datetime.now()\n",
        "print(t1-t0)"
      ],
      "metadata": {
        "id": "jIKjn-tlPO4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case your computer crashes, or for what ever reason, you need to start over."
      ],
      "metadata": {
        "id": "Y52tW3KZclD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "functional_model_trans.load_weights('/content/my_model_chk.weights.h5')\n",
        "history_ck = functional_model_trans.fit(\n",
        "    train_data_IDFD,\n",
        "    epochs=5,  # Resume for more epochs\n",
        "    validation_data=test_data_IDFD,\n",
        "    callbacks=[chk_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "rKmyH9zTckMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Imagine , ytour friend in USA , is interested to repeat your work. and you want to only give him the weights, because the whole model is a large file... so he can build the model himself, and NOT train it, BUT , import your weights into her model"
      ],
      "metadata": {
        "id": "Vvc623v6oKrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights to a file\n",
        "functional_model_trans.save_weights('model_weights.weights.h5')\n",
        "print(\"Weights saved to 'model_weights\")"
      ],
      "metadata": {
        "id": "bedYHFQ4dpTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Your friends model, she will call it model 5\n",
        "\n",
        "input = layers.Input(shape=input_shape, name='Input')  # Define the input layer\n",
        "\n",
        "# Apply data augmentation\n",
        "x = data_augmentation(input)\n",
        "\n",
        "# Attach the pre-trained transfer learning model\n",
        "x = trans_model(x, training=False)  # Freeze the pre-trained weights\n",
        "print(f'After Transfer Learning Model: {x.shape}')\n",
        "\n",
        "# Global Average Pooling to reduce dimensions\n",
        "x = layers.GlobalAveragePooling2D(name='Global_Avg_Pooling')(x)\n",
        "print(f'After Global Average Pooling: {x.shape}')\n",
        "\n",
        "# Output layer for classification\n",
        "output = layers.Dense(10, activation='softmax', name='Output_Layer')(x)\n",
        "\n",
        "# Create your friend's model\n",
        "friends_model = tf.keras.Model(inputs=input, outputs=output, name='Friends_Model')\n",
        "\n",
        "# Compile the model\n",
        "friends_model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "zvlrOQzoTwD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your friend is going to use your weights, by using the .load_weights() function"
      ],
      "metadata": {
        "id": "EJ_T9QgmosMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the weights into the friend's model\n",
        "friends_model.load_weights('/content/model_weights.weights.h5')\n",
        "print(\"Weights loaded successfully!\")"
      ],
      "metadata": {
        "id": "_QWv9CmEUVAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, your friend can try and see if your model is rubbish or as good as you claim :)"
      ],
      "metadata": {
        "id": "S763v9gTpMaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "loss, accuracy = friends_model.evaluate(test_data_IDFD, verbose=1)\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4%}\")"
      ],
      "metadata": {
        "id": "lW0G9kJOew1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "720/32"
      ],
      "metadata": {
        "id": "l2M77nwejZeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And overall to make predictions......"
      ],
      "metadata": {
        "id": "GFluSQzye5c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = friends_model.predict(test_data_IDFD)"
      ],
      "metadata": {
        "id": "jSjcq2l_Uqmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "print(predicted_classes)"
      ],
      "metadata": {
        "id": "Vr6CsPNJpWiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, if you want to test it with some image that has never been in your original data...  REAL testing I mean"
      ],
      "metadata": {
        "id": "WSX4MlWbfpT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = 'path_to_your_image.jpg'  # Replace with your image path\n",
        "img = load_img(image_path, target_size=(224, 224))  # Resize image, deffinitly do this\n",
        "img_array = img_to_array(img)  # Convert image to array\n",
        "img_array = img_array / 255.0  # Normalize to [0, 1] range\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "# Make a prediction\n",
        "prediction = friends_model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction, axis=1)\n",
        "print(f\"Predicted class: {test_data_IDFD.class_names[predicted_class[0]]}\")"
      ],
      "metadata": {
        "id": "TpKLjZHxpYU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THATS it"
      ],
      "metadata": {
        "id": "q4X5DHa4ga3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh, in case you want to do More augmentation, using the Sequential Augmentation....we prepared:"
      ],
      "metadata": {
        "id": "Pv0pf_QegdBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Input layer\n",
        "inputs = layers.Input(shape=input_shape, name='Input')\n",
        "\n",
        "# Apply data augmentation\n",
        "x = data_augmentation(inputs)  # This is absically  Dynamically augment the data during training<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<                                 Here\n",
        "\n",
        "# Attach the pre-trained transfer learning model\n",
        "x = trans_model(x, training=False)  # Use the frozen pre-trained model\n",
        "print(f\"After Transfer Learning Model: {x.shape}\")\n",
        "\n",
        "# Global Average Pooling\n",
        "x = layers.GlobalAveragePooling2D(name='Global_Avg_Pooling')(x)\n",
        "print(f\"After Global Average Pooling: {x.shape}\")\n",
        "\n",
        "# Output layer\n",
        "outputs = layers.Dense(10, activation='softmax', name='Output_Layer')(x)\n",
        "\n",
        "# Create the model\n",
        "friends_model = tf.keras.Model(inputs=inputs, outputs=outputs, name='Friends_Model')\n",
        "\n",
        "# Compile the model\n",
        "friends_model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print the model summary\n",
        "friends_model.summary()"
      ],
      "metadata": {
        "id": "sYaJMdCPgkQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your mate saving the entire model"
      ],
      "metadata": {
        "id": "0YJcMTLil801"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "friends_model.save('friends_model_with_optimizer.h5')"
      ],
      "metadata": {
        "id": "Eb2MKM-Ul20_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "friends_model = load_model('friends_model_with_optimizer.h5')"
      ],
      "metadata": {
        "id": "gM_k6vaDl4WP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}